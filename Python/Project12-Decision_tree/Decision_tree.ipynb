{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 12 - Decision Tree - using Python\n",
    "## Nhi Le\n",
    "## DATA 4319 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision tree** builds classification or regression models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes. A decision node (e.g., Outlook) has two or more branches (e.g., Sunny, Overcast and Rainy). Leaf node (e.g., Play) represents a classification or decision. The topmost decision node in a tree which corresponds to the best predictor called root node. Decision trees can handle both categorical and numerical data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.saedsayad.com/images/Decision_Tree_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm**\n",
    "\n",
    "Decision Tree algorithm belongs to the family of supervised learning algorithms. Unlike other supervised learning algorithms, the decision tree algorithm can be used for solving regression and classification problems too.\n",
    "\n",
    "The goal of using a Decision Tree is to create a training model that can use to predict the class or value of the target variable by learning simple decision rules inferred from prior data(training data).\n",
    "\n",
    "In Decision Trees, for predicting a class label for a record we start from the root of the tree. We compare the values of the root attribute with the record’s attribute. On the basis of comparison, we follow the branch corresponding to that value and jump to the next node.\n",
    "\n",
    "**Types of Decision Trees**\n",
    " \n",
    "Types of decision trees are based on the type of target variable we have. It can be of two types:\n",
    "\n",
    "* _Categorical Variable Decision Tree:_ Decision Tree which has a categorical target variable then it called a Classification\n",
    "\n",
    "* _Continuous Variable Decision Tree:_ Decision Tree has a continuous target variable then it is called Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(array):\n",
    "    dic={}\n",
    "    for i in np.unique(array):\n",
    "        dic.update({i:np.where(array==i)[0]})\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([0], dtype=int64), 1: array([1], dtype=int64), 2: array([2], dtype=int64)}\n",
      "{0: array([1, 3, 4, 6], dtype=int64), 1: array([0, 2, 5], dtype=int64)}\n",
      "{0: array([1, 4], dtype=int64), 1: array([0, 5, 6], dtype=int64), 2: array([3], dtype=int64), 3: array([2], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "print(split(np.array([0,1,2])))\n",
    "print(split(np.array([1,0,1,0,0,1,0])))\n",
    "print(split(np.array([1,0,3,2,0,1,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy\n",
    "\n",
    "**Entropy** controls how a Decision Tree decides to split the data. It actually effects how a Decision Tree draws its boundaries. Entropy is the measures of impurity, disorder or uncertainty in a bunch of examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mathematical formula for Entropy is as follows:\n",
    "\n",
    "![](https://miro.medium.com/max/587/1*nNY_7_aWRwp8E2DyGduEPg.png)\n",
    "![](https://miro.medium.com/max/3600/1*S6zcbdAzUvIOKBaWBKp9MA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def entropy(array):\n",
    "    b_list=[]\n",
    "    for i in np.unique(array):\n",
    "        p=len(np.where(array==i)[0])/len(array)\n",
    "        b_list.append(p*math.log2(p))\n",
    "    return -sum(b_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "-0.0\n",
      "0.4395\n",
      "-0.0\n",
      "1.6577\n"
     ]
    }
   ],
   "source": [
    "print(round(entropy(np.array([0,1,0,1,1,0])),4))\n",
    "print(round(entropy(np.array([1,2])),4))\n",
    "print(round(entropy(np.array([1,1])),4))\n",
    "print(round(entropy(np.array([1,0,0,0,0,0,0,0,0,0,0])),4))\n",
    "print(round(entropy(np.array([0,0,0])),4))\n",
    "print(round(entropy(np.array([1,1,1,0,1,4,4,2,1])),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information gain (IG)\n",
    "\n",
    "**Information gain (IG)** measures how much “information” a feature gives us about the class.\n",
    "\n",
    "![](https://miro.medium.com/max/3600/1*bVGWGETTor7bSnhr7sXEVw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why it matter ?**\n",
    "* Information gain is the main key that is used by Decision Tree Algorithms to construct a Decision Tree.\n",
    "\n",
    "* Decision Trees algorithm will always tries to maximize Information gain.\n",
    "\n",
    "* An attribute with highest Information gain will tested/split first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IG(x,y):\n",
    "    parent_entropy=entropy(y)\n",
    "    split_dict=[split(x).get(k) for k in np.unique(x)]\n",
    "    for i in split_dict:\n",
    "        freq=len(x[[k for k in i]])/len(x)\n",
    "        child_entropy=freq*entropy(y[[k for k in i]])\n",
    "        parent_entropy=parent_entropy-child_entropy\n",
    "    return parent_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4591\n",
      "0.2516\n",
      "0.9183\n"
     ]
    }
   ],
   "source": [
    "x=np.array([0,1,0,1,0,1])\n",
    "y=np.array([0,1,0,1,1,1])\n",
    "print(round(IG(x,y),4))\n",
    "x=np.array([0,0,1,1,2,2])\n",
    "y=np.array([0,1,0,1,1,1])\n",
    "print(round(IG(x,y),4))\n",
    "x=np.array([0,1,0,1,2,1])\n",
    "y=np.array([0,1,0,1,1,1])\n",
    "print(round(IG(x,y),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tree(X,y,attribute):\n",
    "    if y.shape[0]==1 or y.shape[0]==0:\n",
    "        return y\n",
    "\n",
    "    gains=[]\n",
    "    if len(X.T)==1:\n",
    "        gain=IG(X.T,y)\n",
    "        if (gain<=1e-05):\n",
    "            return y\n",
    "        gains.append(gain)\n",
    "    else:\n",
    "        for x in X.T:\n",
    "            gain=IG(x,y)\n",
    "\n",
    "            if (gain<=1e-05):\n",
    "                return y\n",
    "\n",
    "            gains.append(gain)\n",
    "    #print(gains)\n",
    "    best_feature=np.argmax(gains)\n",
    "    #print(best_feature)\n",
    "    results={}\n",
    "    \n",
    "    subset_dict=split(X[:,best_feature])\n",
    "    #print(subset_dict)\n",
    "    for feature_value,train_example_indices in subset_dict.items():\n",
    "        #print(train_example_indices)\n",
    "        child_x_subset=np.delete(X[train_example_indices],best_feature,1)\n",
    "        child_y_subset=y[train_example_indices]\n",
    "        child_attribute=attribute[attribute != attribute[best_feature]]\n",
    "        #print(child_x_subset)\n",
    "\n",
    "        results[\"%s = %s\" %(attribute[best_feature], feature_value)] = make_tree(child_x_subset, child_y_subset,child_attribute)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=pd.read_csv(\"dataset/tennis.csv\").iloc[:,1:-1].values\n",
    "y=pd.read_csv(\"dataset/tennis.csv\").iloc[:,-1].values\n",
    "attribute=pd.read_csv(\"dataset/tennis.csv\").iloc[:,1:-1].columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree model for dataset Tennis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://scontent.xx.fbcdn.net/v/t1.15752-9/129871522_1049163618884219_2704732472935006068_n.png?_nc_cat=106&ccb=2&_nc_sid=ae9488&_nc_ohc=2RaH9P7stxgAX_K73tM&_nc_ad=z-m&_nc_cid=0&_nc_ht=scontent.xx&oh=25e2e5dcb03975620c1d92794161bf32&oe=5FF3A1C6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     outlook  temp humidity    wind play\n",
       "0      Sunny   Hot     High    Weak   No\n",
       "1      Sunny   Hot     High  Strong   No\n",
       "2   Overcast   Hot     High    Weak  Yes\n",
       "3       Rain  Mild     High    Weak  Yes\n",
       "4       Rain  Cool   Normal    Weak  Yes\n",
       "5       Rain  Cool   Normal  Strong   No\n",
       "6   Overcast  Cool   Normal  Strong  Yes\n",
       "7      Sunny  Mild     High    Weak   No\n",
       "8      Sunny  Cool   Normal    Weak  Yes\n",
       "9       Rain  Mild   Normal    Weak  Yes\n",
       "10     Sunny  Mild   Normal  Strong  Yes\n",
       "11  Overcast  Mild     High  Strong  Yes\n",
       "12  Overcast   Hot   Normal    Weak  Yes\n",
       "13      Rain  Mild     High  Strong   No"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golf_df=pd.read_csv(\"dataset/tennis.csv\").iloc[:,1:]\n",
    "golf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['outlook' 'temp' 'humidity' 'wind']\n",
      "[['Sunny' 'Hot' 'High' 'Weak']\n",
      " ['Sunny' 'Hot' 'High' 'Strong']\n",
      " ['Overcast' 'Hot' 'High' 'Weak']\n",
      " ['Rain' 'Mild' 'High' 'Weak']\n",
      " ['Rain' 'Cool' 'Normal' 'Weak']\n",
      " ['Rain' 'Cool' 'Normal' 'Strong']\n",
      " ['Overcast' 'Cool' 'Normal' 'Strong']\n",
      " ['Sunny' 'Mild' 'High' 'Weak']\n",
      " ['Sunny' 'Cool' 'Normal' 'Weak']\n",
      " ['Rain' 'Mild' 'Normal' 'Weak']\n",
      " ['Sunny' 'Mild' 'Normal' 'Strong']\n",
      " ['Overcast' 'Mild' 'High' 'Strong']\n",
      " ['Overcast' 'Hot' 'Normal' 'Weak']\n",
      " ['Rain' 'Mild' 'High' 'Strong']]\n",
      "label\n",
      " ['No' 'No' 'Yes' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes' 'Yes' 'Yes' 'Yes' 'Yes'\n",
      " 'No']\n",
      "decision tree:\n",
      " {'outlook = Overcast': array(['Yes', 'Yes', 'Yes', 'Yes'], dtype=object), 'outlook = Rain': {'wind = Strong': array(['No', 'No'], dtype=object), 'wind = Weak': array(['Yes', 'Yes', 'Yes'], dtype=object)}, 'outlook = Sunny': {'humidity = High': array(['No', 'No', 'No'], dtype=object), 'humidity = Normal': array(['Yes', 'Yes'], dtype=object)}}\n"
     ]
    }
   ],
   "source": [
    "print(attribute)\n",
    "print(x)\n",
    "print(\"label\\n\",y)\n",
    "print(\"decision tree:\\n\",make_tree(x,y,attribute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _traverse(x,d,attribute):\n",
    "    if isinstance(d,np.ndarray):\n",
    "        return d\n",
    "    for key in d:\n",
    "        name,value=key.split(\"=\")\n",
    "        feature_idx=attribute.tolist().index(name.strip())\n",
    "        if x[feature_idx]==value.strip():\n",
    "            return _traverse(x,d[key],attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'Yes', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "_traverse(np.array(['Rain','Mild','High','Weak']),make_tree(x,y,attribute),attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the answer is \"Yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'Yes', 'Yes', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_traverse(np.array(['Overcast','Cool','High','Weak']),make_tree(x,y,attribute),attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the answer is \"Yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: ['No' 'No' 'No']\n",
      "lable: No\n",
      "predict: ['No' 'No' 'No']\n",
      "lable: No\n",
      "predict: ['Yes' 'Yes' 'Yes' 'Yes']\n",
      "lable: Yes\n",
      "predict: ['Yes' 'Yes' 'Yes']\n",
      "lable: Yes\n",
      "predict: ['Yes' 'Yes' 'Yes']\n",
      "lable: Yes\n",
      "predict: ['No' 'No']\n",
      "lable: No\n",
      "predict: ['Yes' 'Yes' 'Yes' 'Yes']\n",
      "lable: Yes\n",
      "predict: ['No' 'No' 'No']\n",
      "lable: No\n",
      "predict: ['Yes' 'Yes']\n",
      "lable: Yes\n",
      "predict: ['Yes' 'Yes' 'Yes']\n",
      "lable: Yes\n",
      "predict: ['Yes' 'Yes']\n",
      "lable: Yes\n",
      "predict: ['Yes' 'Yes' 'Yes' 'Yes']\n",
      "lable: Yes\n",
      "predict: ['Yes' 'Yes' 'Yes' 'Yes']\n",
      "lable: Yes\n",
      "predict: ['No' 'No']\n",
      "lable: No\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(golf_df.iloc[:,:-1].values,golf_df['play']):\n",
    "    print(\"predict:\",_traverse(i,make_tree(x,y,attribute),attribute))\n",
    "    print('lable:',j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: \n",
    "All prediction is correct. Decision trees use multiple algorithms to decide to split a node into two or more sub-nodes. The creation of sub-nodes increases the homogeneity of resultant sub-nodes. In other words, we can say that the purity of the node increases with respect to the target variable. The decision tree splits the nodes on all available variables and then selects the split which results in most homogeneous sub-nodes.\n",
    "\n",
    "**Reference:** https://medium.com/coinmonks/what-is-entropy-and-why-information-gain-is-matter-4e85d46d2f01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
